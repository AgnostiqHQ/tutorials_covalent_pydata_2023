{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-compute workflow orchestration with [*Covalent*](http://covalent.xyz).\n",
    "\n",
    "Run complex workflows with ease; using cloud, on-prem, and/or local backends.\n",
    "\n",
    "## Covalent is available from PYPI\n",
    "\n",
    "```\n",
    "$ pip install covalent\n",
    "```\n",
    "\n",
    "## Usage\n",
    "\n",
    "👉 Add one or more [@ct.electron](https://docs.covalent.xyz/docs/user-documentation/concepts/covalent-basics#electron) decorators to designate workflow tasks (i.e. *electrons*).\n",
    "\n",
    "👉 Specify [executors](https://docs.covalent.xyz/docs/plugin) to choose electron backends.\n",
    "\n",
    "\n",
    "# 🔗 See links below for more information!\n",
    "\n",
    "- 🌟 [Covalent GitHub](https://github.com/AgnostiqHQ/covalent)\n",
    "- 📚 [Covalent Documentation](https://docs.covalent.xyz)\n",
    "- ✍️ [Covalent Blogs](https://www.covalent.xyz/blog/)\n",
    "    - [Simplifying generative AI workflows with Covalent and Streamlit](https://blog.streamlit.io/simplifying-generative-ai-workflows/)\n",
    "    - [Improving Chest X-ray Pneumonia Detection with Federated Learning and Covalent](https://medium.com/@filip_98594/improving-chest-x-ray-pneumonia-detection-with-federated-learning-and-covalent-ff60eef7946c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "Run the following commands to create and activate the environment:\n",
    "```shell\n",
    "$ conda env create -f \"environment.yml\"\n",
    "$ conda activate covalent_pydata_2023\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Infrastructure\n",
    "\n",
    "See `terraform/tutorial-llm/README.md` for instructions on how to create the infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Covalent\n",
    "\n",
    "Run the following command to start Covalent:\n",
    "\n",
    "```shell\n",
    "$ covalent start\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL: AI Image Generator for Wikipedia Articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get an assertion error from the cell below: Shut down the notebook kernel, run the command below, then restart the notebook kernel from the same shell.\n",
    "\n",
    "```shell\n",
    "$ export COVALENT_EXEC_BASE_URI=\"public.ecr.aws/m8q0y4d2/covalent-executor-pydata2023:cuda-12.1.0\"\n",
    "```\n",
    "\n",
    "The next release of `covalent-awsbatch-plugin` (`>0.40.0`) exposes this functionality as an `AWSBatchExecutor` argument, [`container_image_uri`](https://github.com/AgnostiqHQ/covalent-awsbatch-plugin/blob/e58a1bc413999322bbc469408142af68f4c08cb4/covalent_awsbatch_plugin/awsbatch.py#L114).\n",
    "\n",
    "We'll use the environment variable for now - make sure its set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "assert os.environ[\"COVALENT_EXEC_BASE_URI\"] == \"public.ecr.aws/m8q0y4d2/covalent-executor-pydata2023:cuda-12.1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "from typing import Any, List\n",
    "\n",
    "import covalent as ct\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from wikipediaapi import Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Settings for Executor (convenience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ct.get_config(\"executors.awsbatch\")\n",
    "\n",
    "# Update the `config` dictionary with new values.\n",
    "config.update(\n",
    "    credentials = \"/Users/me/.aws/my_credentials\",  # must be up to date\n",
    "    profile = \"default\",                            # must match credentials\n",
    "    batch_execution_role_name = \"covalent-pydata2023-task-execution-role\",\n",
    "    batch_job_log_group_name = \"covalent-pydata2023-log-group\",\n",
    "    batch_job_role_name = \"covalent-pydata2023-job-role\",\n",
    "    batch_queue = \"covalent-pydata2023-queue\",\n",
    "\n",
    "    # NOTE: This name will be unique. Be sure to update it.\n",
    "    s3_bucket_name = \"covalent-pydata2023-tn1g5duw\",\n",
    ")\n",
    "\n",
    "# Set the executor's config after updating.\n",
    "ct.set_config(\"executors.awsbatch\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare some constants.\n",
    "MAX_LENGTH_PROMPT = 77\n",
    "INPUT_BLANK = \"summarize: {text}\"  # format prompt text into this\n",
    "TOKENIZER_MODEL = \"t5-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, some useful helper code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Post processor class that will render the outputted images in this Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PostProcessor:\n",
    "    \"\"\"Post-process the generated images and summaries.\"\"\"\n",
    "\n",
    "    # Regex pattern for splitting sentences.\n",
    "    _end_sentence_pattern = r\"(?<=[.!?])\\s+(?=[a-z])\"\n",
    "\n",
    "    # HTML template for displaying image-summary pairs.\n",
    "    _html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    <h2>{title}</h2>\n",
    "    <img src=\"data:image/jpeg; base64,{src}\" alt=\"{src}\">\n",
    "    <p style=\"font-size:18px\">{summary}</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        section_names: List[str],\n",
    "        summaries: List[str],\n",
    "        images: List[Any],\n",
    "    ):\n",
    "\n",
    "        self.section_names = self._process_sections(section_names)\n",
    "        self.summaries = self._process_summaries(summaries)\n",
    "        self.images = images\n",
    "\n",
    "    @property\n",
    "    def contents(self) -> List[tuple]:\n",
    "        return list(zip(self.section_names, self.summaries, self.images))\n",
    "\n",
    "    @classmethod\n",
    "    def _process_summaries(cls, summaries: List[str]) -> List[str]:\n",
    "        \"\"\"Apply aesthetic clean-ups to the summaries.\"\"\"\n",
    "\n",
    "        _summaries = []\n",
    "        for summary in summaries:\n",
    "            sentences = re.split(cls._end_sentence_pattern, summary)\n",
    "            _summaries.append(' '.join(map(str.capitalize, sentences)))\n",
    "\n",
    "        return _summaries\n",
    "\n",
    "    @staticmethod\n",
    "    def _process_sections(section_names: List[str]) -> List[str]:\n",
    "        \"\"\"Apply aesthetic clean-ups to section names.\"\"\"\n",
    "\n",
    "        _section_names = []\n",
    "        for name in section_names:\n",
    "            words = name.split(' ')\n",
    "            _section_names.append(' '.join(map(str.capitalize, words)))\n",
    "\n",
    "        return _section_names\n",
    "\n",
    "    def display_all(self):\n",
    "        \"\"\"Display title-image-summary for each section.\"\"\"\n",
    "\n",
    "        import base64\n",
    "        from io import BytesIO\n",
    "        from IPython.display import display, HTML\n",
    "\n",
    "        # Render images and embed into notebook.\n",
    "        for section_name, summary, image in self.contents:\n",
    "\n",
    "            # get image as bytes\n",
    "            buffered = BytesIO()\n",
    "            image.save(buffered, format=\"JPEG\")\n",
    "            img_bytes = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "            # save image file\n",
    "            image.save(f\"{section_name}.png\", format=\"PNG\")\n",
    "\n",
    "            display(\n",
    "                HTML(self._html.format(title=section_name, src=img_bytes, summary=summary))\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to retrieve the pre-trained model from download or local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(type_: object, id_: str, label=None, **params):\n",
    "    \"\"\"Download files for the model if necessary and return the model.\"\"\"\n",
    "\n",
    "    _base_dir = Path('/tmp/wiki_image_summary')\n",
    "    if not _base_dir.exists():\n",
    "        _base_dir.mkdir()\n",
    "\n",
    "    model_id = id_.replace('/', '_')\n",
    "    if label:\n",
    "        model_id += f\"_{label}\"\n",
    "\n",
    "    model_path = _base_dir / model_id\n",
    "\n",
    "    if model_path.exists():\n",
    "        return type_.from_pretrained(model_path, **params)\n",
    "\n",
    "    model = type_.from_pretrained(id_, **params)\n",
    "    model.save_pretrained(model_path)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, let's define a workflow!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electrons\n",
    "\n",
    "#### These are the tasks that Covalent will ship to various backends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read from Wikipedia (local execution)\n",
    "A task that uses the Wikipedia API to find an article by name and retrieve text from the specified sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def get_page_sections(\n",
    "    page_title: str,\n",
    "    section_titles: List[str],\n",
    ") -> OrderedDict:\n",
    "    \"\"\"Get the title and text for each section in the page\"\"\"\n",
    "\n",
    "    wiki_wiki = Wikipedia(\"AQUser\", 'en')\n",
    "    page = wiki_wiki.page(page_title)\n",
    "\n",
    "    if not page.exists():\n",
    "        raise RuntimeError(f\"Wikipedia page '{page_title}' not found.\")\n",
    "\n",
    "    section_titles = [s.lower() for s in section_titles]\n",
    "\n",
    "    section_texts = OrderedDict()\n",
    "    for section in page.sections:\n",
    "        section_title = section.title.lower()\n",
    "\n",
    "        if section_title in section_titles:\n",
    "            text_parts = [section.text]\n",
    "            for subsection in section.sections:\n",
    "                text_parts.append(subsection.text)\n",
    "\n",
    "            section_texts[section_title] = '\\n'.join(text_parts)\n",
    "\n",
    "    if len(section_texts) == 0:\n",
    "        raise RuntimeError(\"No text retrieved from any sections.\")\n",
    "\n",
    "    return section_texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Summarize Article Sections (AWSBatch - CPU instance)\n",
    "\n",
    "Here we define the text-to-text model that creates a prompt for the subsequent Stable Diffusion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_awsbatch = ct.executor.AWSBatchExecutor(\n",
    "    vcpu=2,\n",
    "    num_gpus=0,\n",
    "    memory=12,\n",
    "    time_limit=3600\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps_1 = [\"torch==2.1.0\", \"transformers==4.33.1\", \"sentencepiece==0.1.99\"]\n",
    "\n",
    "@ct.electron(executor=cpu_awsbatch, deps_pip=deps_1)\n",
    "def generate_reduced_summaries(\n",
    "    section_texts: OrderedDict,\n",
    "    model_name: str = TOKENIZER_MODEL,\n",
    "    max_length: int = MAX_LENGTH_PROMPT,\n",
    ") -> List[str]:\n",
    "    \"\"\"Generate a `max_length` summary from the batch of text sections.\"\"\"\n",
    "\n",
    "    # Encode the article and generate a title\n",
    "    section_texts_formatted = [\n",
    "        INPUT_BLANK.format(text=section_text)\n",
    "        for section_text in section_texts.values()\n",
    "    ]\n",
    "\n",
    "    # Reduce the full text into a shorter digest.\n",
    "    tokenizer = get_model(T5Tokenizer, model_name, \"tokenizer\", suffix=\"tokenizer\")\n",
    "    inputs = tokenizer(\n",
    "        section_texts_formatted,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=1024,\n",
    "    )\n",
    "\n",
    "    # Generate a `max_length` summary from the digest.\n",
    "    model = get_model(T5ForConditionalGeneration, model_name)\n",
    "    output_sequences = model.generate(\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        do_sample=False,\n",
    "        max_length=max_length,\n",
    "        num_beams=4,\n",
    "        length_penalty=2.0,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "\n",
    "    # Decode the summaries.\n",
    "    summaries = [\n",
    "        tokenizer.decode(output, skip_special_tokens=True)\n",
    "        for output in output_sequences\n",
    "    ]\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.to(\"cpu\")\n",
    "\n",
    "    return summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Generate Images from Summaries (AWSBatch - GPU instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_awsbatch = ct.executor.AWSBatchExecutor(\n",
    "    vcpu=4,\n",
    "    num_gpus=1,  # <--- request 1 GPU per task\n",
    "    memory=12,\n",
    "    time_limit=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps_2 = [\n",
    "    \"accelerate==0.22.0\",\n",
    "    \"torch==2.1.0\",\n",
    "    \"transformers==4.33.1\",\n",
    "    \"diffusers==0.20.2\",\n",
    "]\n",
    "\n",
    "@ct.electron(executor=gpu_awsbatch, deps_pip=deps_2)\n",
    "def generate_images(\n",
    "    prompts: List[str],\n",
    "    width: int,\n",
    "    height: int,\n",
    "    num_inference_steps: int,\n",
    "    *,\n",
    "    model_type: Any = StableDiffusionPipeline,\n",
    "    model_id: str = \"runwayml/stable-diffusion-v1-5\",\n",
    "    **params,\n",
    "):\n",
    "    \"\"\"Generate an image based on a summary prompt.\"\"\"\n",
    "\n",
    "    model = get_model(model_type, model_id, **params)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.to(\"cuda\")\n",
    "\n",
    "    model_output = model(\n",
    "        prompts,\n",
    "        width=width,\n",
    "        height=height,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "    )\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.to(\"cpu\")\n",
    "\n",
    "    return model_output.images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Obtain Post-Processor Object (local execution)\n",
    "\n",
    "This creates an instance of our `PostProcessor` (class created at the top of this notebook), which renders the model outputs in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.electron\n",
    "def post_process(\n",
    "    section_names: List[List[str]],\n",
    "    summaries: List[List[str]],\n",
    "    images: List[List[Any]],\n",
    ") -> PostProcessor:\n",
    "    \"\"\"Post-process and optionally upload the generated images and summaries.\"\"\"\n",
    "\n",
    "    # Flatten once-nested input lists.\n",
    "    summaries = [summary for summaries in summaries for summary in summaries]\n",
    "    images = [image for images in images for image in images]\n",
    "\n",
    "    pp = PostProcessor(section_names, summaries, images)\n",
    "\n",
    "    return pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Lattice'></a>\n",
    "\n",
    "## Lattice\n",
    "\n",
    "#### Definition of the main workflow function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ct.lattice\n",
    "def workflow(\n",
    "    page_title: str,\n",
    "    sections: List[str],\n",
    "    width: int = 800,\n",
    "    height: int = 640,\n",
    "    num_inference_steps: int = 100,\n",
    "    batch_size: int = 2,\n",
    ") -> None:\n",
    "    \"\"\"Retrieve text sections from Wikipedia page. Generate summaries and images.\"\"\"\n",
    "\n",
    "    summaries_all = []\n",
    "    images_all = []\n",
    "\n",
    "    for i in range(0, len(sections), batch_size):\n",
    "\n",
    "        sections_batch = sections[i:i + batch_size]\n",
    "        section_texts = get_page_sections(page_title, sections_batch)\n",
    "        section_text_summaries = generate_reduced_summaries(section_texts)\n",
    "\n",
    "        section_text_images = generate_images(\n",
    "            section_text_summaries,\n",
    "            width,\n",
    "            height,\n",
    "            num_inference_steps,\n",
    "        )\n",
    "\n",
    "        summaries_all.append(section_text_summaries)\n",
    "        images_all.append(section_text_images)\n",
    "\n",
    "    return post_process(sections, summaries_all, images_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispatching...\n",
    "\n",
    "Generate summaries from sections of the Wikipedia entry for the famous Dutch artist M. C. Escher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_TITLE = \"M. C. Escher\"\n",
    "\n",
    "PAGE_SECTIONS = [\n",
    "    \"Early life\",\n",
    "    \"Study journeys\",\n",
    "    \"Later life\",\n",
    "    \"Mathematically inspired work\",\n",
    "    \"Legacy\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispatch_id = ct.dispatch(workflow)(PAGE_TITLE, PAGE_SECTIONS)\n",
    "print(dispatch_id)\n",
    "results = ct.get_result(dispatch_id, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow Graph: Running\n",
    "\n",
    "- Navigate to [http://localhost:48008/](http://localhost:48008/)\n",
    "- Select the corresponding dispatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='center'>\n",
    "<img src=\"https://drive.google.com/uc?id=1H8h7nkfx4m64OWb6g_GBghmaTs3wlRrq\" alt=\"ui running\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting workflow results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_processor = results.result\n",
    "\n",
    "# Render the model outputs.\n",
    "post_processor.display_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
